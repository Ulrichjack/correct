import os
import json
import google.generativeai as genai
from groq import Groq

# Importer la configuration
from app.config import GEMINI_API_KEY, GROQ_API_KEY, AI_PROVIDER

# ====================================
# 1. CONFIGURATION DES CLIENTS API
# ====================================

# Configurer Gemini (si la cl√© est fournie)
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Configurer Groq (si la cl√© est fournie)
client_groq = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY else None


# ====================================
# 2. PROMPT DE CORRECTION DE QUESTION
# ====================================

def _construire_prompt(enonce_question, reponse_etudiant, correction_prof, points_max, numero_question):
    """Construit le prompt pour √©valuer la r√©ponse d'un √©tudiant pour UNE question."""
    return f"""
    Tu es un assistant expert pour un enseignant, sp√©cialis√© dans la correction de copies.
    Ta t√¢che est d'√©valuer la r√©ponse d'un √©tudiant pour la question '{numero_question}'.

    **CONTEXTE DE LA QUESTION ({numero_question})**
    - √ânonc√© de la question : {enonce_question}
    - Points maximum pour cette question : {points_max}

    ---
    **R√âPONSE ATTENDUE (Correction du professeur) :**
    {correction_prof}
    ---

    **R√âPONSE DE L'√âTUDIANT :**
    {reponse_etudiant}
    ---

    **INSTRUCTIONS DE CORRECTION :**
    1.  **Analyse S√©mantique :** Compare la R√âPONSE DE L'√âTUDIANT √† la R√âPONSE ATTENDUE. L'important est le sens, pas les mots exacts.
    2.  **Hors-Sujet :** Si la r√©ponse est compl√®tement hors-sujet, attribue 0 point.
    3.  **Attribution des Points :** Attribue une note sur {points_max}. Sois juste et coh√©rent.
    4.  **Cat√©gorisation :** 'REUSSIE' (proche de la perfection), 'PARTIELLE' (correcte mais incompl√®te), ou 'RATEE' (incorrecte ou hors-sujet).
    5.  **G√©n√©ration de Feedbacks :** R√©dige une annotation courte (max 15 mots), un feedback d√©taill√© (explique les points forts/faibles) et un conseil de r√©vision.

    **FORMAT DE SORTIE OBLIGATOIRE :**
    R√©ponds UNIQUEMENT avec un objet JSON valide avec la structure suivante :
    {{
      "points_obtenus": <nombre>,
      "categorie": "<string>",
      "annotation_courte": "<string>",
      "feedback_detaille": "<string>",
      "conseil_revision": "<string>"
    }}
    """


# ==============================================================
# 3. PROMPT D'EXTRACTION DE BAR√àME
# ==============================================================

def _construire_prompt_bareme(texte_epreuve: str) -> str:
    """Construit un prompt pour demander √† l'IA d'extraire le bar√®me d'un sujet."""
    return f"""
    Tu es un assistant expert capable d'analyser des sujets d'examen.
    Ta t√¢che est de lire le texte d'une √©preuve et d'en extraire le bar√®me sous forme de JSON.

    **TEXTE DE L'√âPREUVE :**
    ---
    {texte_epreuve}
    ---

    **INSTRUCTIONS :**
    1.  Identifie chaque question (ex: "Question 1", "Q2", "Exercice 3").
    2.  Pour chaque question, trouve le nombre de points qui lui est associ√© (ex: "(5 points)", "/ 10 pts", "sur 5").
    3.  Ignore les questions qui n'ont pas de points clairement indiqu√©s.
    4.  Retourne UNIQUEMENT un objet JSON valide. La cl√© doit √™tre le num√©ro de la question (ex: "Q1") et la valeur doit √™tre le nombre de points (un nombre, pas une cha√Æne de caract√®res).

    **EXEMPLE DE FORMAT DE SORTIE ATTENDU :**
    {{
      "Q1": 5,
      "Q2": 10,
      "Q3": 5
    }}

    Si aucun bar√®me n'est trouv√©, retourne un objet JSON vide : {{}}.
    """


# ====================================
# 4. FONCTIONS D'APPEL AUX IA
# ====================================

def _call_gemini(prompt):
    model = genai.GenerativeModel('gemini-1.5-flash-latest')
    response = model.generate_content(prompt)
    return response.text


def _call_groq(prompt):
    if not client_groq:
        raise ValueError("La cl√© API Groq n'est pas configur√©e.")
    chat_completion = client_groq.chat.completions.create(
        messages=[{"role": "user", "content": prompt}],
        model="llama-3.1-8b-instant",
        temperature=0.3,
        response_format={"type": "json_object"},
    )
    return chat_completion.choices[0].message.content


# ====================================
# 5. FONCTIONS PRINCIPALES (Services)
# ====================================

def extraire_bareme_de_epreuve(texte_epreuve: str) -> dict:
    """Appelle l'IA pour extraire le bar√®me (points par question) du texte d'une √©preuve."""
    print("ü§ñ Appel de l'IA pour extraire le bar√®me de l'√©preuve...")
    try:
        prompt = _construire_prompt_bareme(texte_epreuve)
        ia_response_text = ""
        if AI_PROVIDER == "gemini":
            ia_response_text = _call_gemini(prompt)
        elif AI_PROVIDER == "groq":
            ia_response_text = _call_groq(prompt)
        else:
            raise ValueError(f"Fournisseur d'IA non reconnu : {AI_PROVIDER}")

        json_text = ia_response_text.strip().replace("```json", "").replace("```", "")
        bareme = json.loads(json_text)

        if not isinstance(bareme, dict):
            raise ValueError("La r√©ponse de l'IA pour le bar√®me n'est pas un dictionnaire.")

        print(f"‚úÖ Bar√®me extrait avec succ√®s : {bareme}")
        return bareme
    except Exception as e:
        print(f"‚ùå ERREUR lors de l'extraction du bar√®me : {e}")
        return {}


def corriger_question(enonce_question: str, reponse_etudiant: str, correction_prof: str, points_max: float,
                      numero_question: str):
    """Appelle l'IA pour corriger une question sp√©cifique et retourne le r√©sultat en JSON."""
    error_response = {
        "points_obtenus": 0, "categorie": "ERREUR", "annotation_courte": "Erreur de correction IA.",
        "feedback_detaille": "Impossible de contacter le service d'IA.",
        "conseil_revision": "V√©rifiez la connexion et les cl√©s API."
    }
    try:
        prompt = _construire_prompt(enonce_question, reponse_etudiant, correction_prof, points_max, numero_question)
        ia_response_text = ""
        if AI_PROVIDER == "gemini":
            ia_response_text = _call_gemini(prompt)
        elif AI_PROVIDER == "groq":
            ia_response_text = _call_groq(prompt)
        else:
            raise ValueError(f"Fournisseur d'IA non reconnu ou non support√© : {AI_PROVIDER}")

        json_text = ia_response_text.strip().replace("```json", "").replace("```", "")
        result = json.loads(json_text)
        return result
    except Exception as e:
        print(f"‚ùå ERREUR dans ai_service.py (corriger_question) : {e}")
        return error_response