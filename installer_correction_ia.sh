#!/bin/bash
set -e

echo "üîß Installation du syst√®me de correction OCR avec IA"
echo "===================================================================="

# 1. Activer l'environnement virtuel
source venv/bin/activate

# 2. V√©rifier que groq est install√©
echo "üì¶ V√©rification des d√©pendances..."
pip install groq python-dotenv --quiet

# 3. Cr√©er le script de correction IA
echo "üìù Cr√©ation du script corriger_avec_ia.py..."
cat > corriger_avec_ia.py << 'PYEOF'
#!/usr/bin/env python3
"""
Corrige les erreurs OCR avec l'IA Groq
"""
import sys
import os
import easyocr
from groq import Groq
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

def main():
    if len(sys.argv) < 2:
        print("Usage: python3 corriger_avec_ia.py <image>")
        sys.exit(1)
    
    image_path = sys.argv[1]
    
    # V√©rifier la cl√© API
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        print("‚ùå GROQ_API_KEY non trouv√©e dans .env !")
        sys.exit(1)
    
    # 1. OCR brut
    print("üì∏ Extraction OCR (EasyOCR)...")
    reader = easyocr.Reader(['fr'], gpu=False, verbose=False)
    result = reader.readtext(image_path, detail=0, paragraph=True)
    texte_brut = "\n".join(result)
    
    print("\n" + "="*70)
    print("üìù TEXTE BRUT (avec erreurs OCR) :")
    print("="*70)
    print(texte_brut)
    print("="*70)
    print(f"Longueur : {len(texte_brut)} caract√®res\n")
    
    # 2. Correction IA
    print("ü§ñ Correction avec Groq IA (llama-3.3-70b)...")
    client = Groq(api_key=api_key)
    
    prompt = f"""Tu es un correcteur d'OCR expert en fran√ßais.
Le texte suivant provient d'une copie d'examen manuscrite (SQL/Base de donn√©es).

T√ÇCHE : Corrige UNIQUEMENT les erreurs √©videntes d'OCR (fautes de frappe, symboles mal reconnus).
- Garde la M√äME structure
- Garde le M√äME contenu
- Ne change PAS le sens
- Corrige les mots d√©form√©s

TEXTE OCR :
{texte_brut}

TEXTE CORRIG√â (garde le m√™me format) :"""
    
    response = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
        max_tokens=2000
    )
    
    texte_corrige = response.choices[0].message.content
    
    print("\n" + "="*70)
    print("‚ú® TEXTE CORRIG√â PAR IA :")
    print("="*70)
    print(texte_corrige)
    print("="*70)
    print(f"Longueur : {len(texte_corrige)} caract√®res")
    
    # 3. Statistiques
    tokens_used = response.usage.total_tokens
    print("\n" + "="*70)
    print("üìä STATISTIQUES :")
    print("="*70)
    print(f"  ‚Ä¢ Tokens utilis√©s : {tokens_used}")
    print(f"  ‚Ä¢ Co√ªt : GRATUIT (Groq)")
    print("="*70)

if __name__ == "__main__":
    main()
PYEOF

chmod +x corriger_avec_ia.py

echo ""
echo "‚úÖ Installation termin√©e !"
echo ""

